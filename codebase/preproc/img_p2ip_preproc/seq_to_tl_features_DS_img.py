import os
import sys
from pathlib import Path

import joblib
import pandas as pd

path_root = Path(__file__).parents[2]  # upto 'codebase' folder
sys.path.insert(0, str(path_root))
# print(sys.path)

from utils import preproc_tl_util_DS_img


# parse the content of allSeqs.fasta and create a dataframe containing 'prot_id' and 'seq' columns
def parse_DS_to_fasta(root_path='./', spec_type = 'human'):
    print('\n########## spec_type: ' + str(spec_type))
    f = open(os.path.join(root_path, 'dataset/orig_data_DS/seqs', spec_type + '.fasta'))
    prot_lst, seq_lst = [], []
    idx = 0
    for line in f:
        if idx == 0:
            prot_lst.append(line.strip().strip('>'))
        elif idx == 1:
            seq_lst.append(line.strip())
        idx += 1
        idx = idx % 2
    f.close()

    # create dataframe
    DS_seq_df = pd.DataFrame(data = {'prot_id': prot_lst, 'seq': seq_lst})
    DS_seq_df['seq_len'] = DS_seq_df['seq'].str.len()

    # save DS_seq_df
    DS_seq_df.to_csv(os.path.join(root_path, 'dataset/preproc_data_DS', 'DS_' + spec_type + '_seq.csv'), index=False)
    # return DS_seq_df
    return DS_seq_df


# add features generated by the protTrans model (tl model) to the already saved DS_sequence list 
def prepare_tl_feat_for_DS_seq_for_img(root_path='./', protTrans_model_path='./', protTrans_model_name = 'prot_t5_xl_uniref50', spec_type = 'human'):
    print('\n########## spec_type: ' + str(spec_type))
    # fetch the already saved DS_sequence df
    print('\n ########## fetch the already saved DS_sequence df ######g#### ')
    DS_seq_df = pd.read_csv(os.path.join(root_path,'dataset/preproc_data_DS', 'DS_' + spec_type + '_seq.csv'))
    # extract features using the protTrans model (tl model) for the DS_sequence list
    print('\n ########## extract features using the protTrans model (tl model) for the DS_sequence list ########## ')
    features_lst, features_2d_lst  = preproc_tl_util_DS_img.extract_feat_from_protTrans(DS_seq_df['seq'].tolist(), protTrans_model_path, protTrans_model_name, spec_type)
    # use the extracted features alongwith DS_seq_df to create a dictionary to be saved as pkl file
    print('\n ########## use the extracted features alongwith DS_seq_df to create a dictionary to be saved as pkl file ########## ')
    DS_seq_feat_dict = {}
    for index, row in DS_seq_df.iterrows():
        DS_seq_feat_dict[row['prot_id']] = {'seq': row['seq'], 'seq_len': row['seq_len'], 'seq_2d_feat': features_2d_lst[index]}
    # save DS_seq_feat_dict to a .pkl file
    print("\n Saving DS_seq_feat_dict to a .pkl file...")
    filename = os.path.join(root_path, 'dataset/preproc_data_DS', 'DS_seq_feat_dict_' + protTrans_model_name + '_' + spec_type + '_img.pkl')
    joblib.dump(value=DS_seq_feat_dict, filename=filename, compress=3)
    print("\n The DS_seq_feat_dict is saved as: " + filename)
    print("\n######## cleaning all the intermediate stuffs - START ########")
    # remove all the intermediate files in the 'temp_result' and 'temp_per_prot_emb_result' directories which
    # were used in extract_feat_from_preloaded_protTrans() method
    temp_result_dir = os.path.join(root_path, 'temp_result_' + spec_type) 
    for temp_file in os.listdir(temp_result_dir):
        os.remove(os.path.join(temp_result_dir, temp_file))
    temp_per_prot_emb_result_dir = os.path.join(root_path, 'temp_per_prot_emb_result_' + spec_type) 
    for temp_file in os.listdir(temp_per_prot_emb_result_dir):
        os.remove(os.path.join(temp_per_prot_emb_result_dir, temp_file))
    print("######## cleaning all the intermediate stuffs - DONE ########")


def create_2d_tl_feat_dict_dump(root_path='./', spec_type = 'human'):
    print('\n########## spec_type: ' + str(spec_type))
    # load twoD_prot_feat_dict from pkl file
    twoD_prot_feat_dict_fl_nm_with_path = os.path.join(root_path, 'dataset/preproc_data_DS', 'DS_seq_feat_dict_prot_t5_xl_uniref50_' + spec_type + '_img.pkl')
    twoD_prot_feat_dict = joblib.load(twoD_prot_feat_dict_fl_nm_with_path)
    print("twoD_prot_feat_dict loaded ...")
    # trimming twoD_prot_feat_dict so that it occupies less memory (RAM)
    for prot_id in list(twoD_prot_feat_dict.keys()):
        twoD_prot_feat_dict[prot_id]['seq'] = twoD_prot_feat_dict[prot_id]['seq_len'] = None
    # iterate through the twoD_prot_feat_dict
    key_lst_in_twoD_prot_feat_dict = list(twoD_prot_feat_dict.keys())
    no_of_keys_in_twoD_prot_feat_dict = len(key_lst_in_twoD_prot_feat_dict)

    # for itr in range(no_of_keys_in_twoD_prot_feat_dict):
    for itr in range(0, no_of_keys_in_twoD_prot_feat_dict):
        print(f"\n ################# spec_type: {spec_type} :: starting {itr}-th iteration out of {no_of_keys_in_twoD_prot_feat_dict-1}")
        prot_id = key_lst_in_twoD_prot_feat_dict[itr]
        prot_2dArr = twoD_prot_feat_dict[prot_id]['seq_2d_feat']
        # save prot_2dArr as a pkl file
        prot_2dArr_file_nm_loc = os.path.join(root_path, 'dataset/preproc_data_DS/tl_2d_feat_dict_dump_img', spec_type, f"prot_id_{prot_id}.pkl")
        joblib.dump(value=prot_2dArr, filename=prot_2dArr_file_nm_loc, compress=0)
    # end of for loop: for itr in range(0, no_of_keys_in_twoD_prot_feat_dict): 

    # for human, create partial twoD_prot_feat_dict which can be safely loaded in the RAM
    if(spec_type == 'human'):
        print('for human, creating partial twoD_prot_feat_dict which can be safely loaded in the RAM')
        partial_twoD_prot_feat_dict = {}
        for itr in range(0, no_of_keys_in_twoD_prot_feat_dict //3):
            print(f"\n ################# spec_type: {spec_type} :: starting {itr}-th iteration out of {(no_of_keys_in_twoD_prot_feat_dict-1) //3}")
            prot_id = key_lst_in_twoD_prot_feat_dict[itr]
            prot_2dArr = twoD_prot_feat_dict[prot_id]['seq_2d_feat']
            partial_twoD_prot_feat_dict[prot_id] = prot_2dArr
        # end of for loop: for itr in range(0, no_of_keys_in_twoD_prot_feat_dict //3):
        # save partial_twoD_prot_feat_dict as a pkl file
        twoD_prot_feat_dict = None
        partial_twoD_prot_feat_dict_file_nm_loc = os.path.join(root_path, 'dataset/preproc_data_DS/tl_2d_feat_dict_dump_img', spec_type, "partial_twoD_prot_feat_dict_oneThird.pkl")
        joblib.dump(value=partial_twoD_prot_feat_dict, filename=partial_twoD_prot_feat_dict_file_nm_loc, compress=3)




if __name__ == '__main__':
    root_path = os.path.join('/project/root/directory/path/here')
    

    spec_type = 'human'  # human, ecoli, fly, mouse, worm, yeast 
    # parse_DS_to_fasta(root_path, spec_type)

    # prepare_tl_feat_for_DS_seq_for_img(root_path
    #                                 ,protTrans_model_path=os.path.join(root_path, '../ProtTrans_Models/')
    #                                 , protTrans_model_name = 'prot_t5_xl_uniref50'
    #                                 , spec_type = spec_type)

    # for dumping each individual 2d tl feature matrix
    # spec_type_lst = ['human', 'ecoli', 'fly', 'mouse', 'worm', 'yeast']
    spec_type_lst = ['human']
    for spec_type in spec_type_lst:
        create_2d_tl_feat_dict_dump(root_path=root_path, spec_type=spec_type)
