import os
import sys
from pathlib import Path

import joblib
import pandas as pd

path_root = Path(__file__).parents[2]  # upto 'codebase' folder
sys.path.insert(0, str(path_root))
# print(sys.path)

from utils import preproc_tl_util_dock_img


# add features generated by the protTrans model (tl model) to the already saved DS_sequence list 
def prepare_tl_feat_for_dock_seq_for_img(root_path='./', protTrans_model_path='./', protTrans_model_name = 'prot_t5_xl_uniref50'
                                         , docking_version = '4_0'):
    # fetch the already saved dock_sequence df
    print('\n ########## fetch the already saved dock_sequence df ######g#### ')
    dock_seq_df = pd.read_csv(os.path.join(root_path,'dataset/preproc_data_docking_BM_' + str(docking_version), 'dock_seq.csv'))
    # extract features using the protTrans model (tl model) for the dock_sequence list
    print('\n ########## extract features using the protTrans model (tl model) for the dock_sequence list ########## ')
    features_lst, features_2d_lst  = preproc_tl_util_dock_img.extract_feat_from_protTrans(dock_seq_df['seq'].tolist(), protTrans_model_path, protTrans_model_name)
    # use the extracted features alongwith dock_seq_df to create a dictionary to be saved as pkl file
    print('\n ########## use the extracted features alongwith dock_seq_df to create a dictionary to be saved as pkl file ########## ')
    dock_seq_feat_dict = {}
    for index, row in dock_seq_df.iterrows():
        dock_seq_feat_dict[row['prot_id']] = {'seq': row['seq'], 'seq_len': len(row['seq']), 'seq_2d_feat': features_2d_lst[index]}
    # save dock_seq_feat_dict to a .pkl file
    print("\n Saving dock_seq_feat_dict to a .pkl file...")
    filename = os.path.join(root_path, 'dataset/preproc_data_docking_BM_' + str(docking_version), 'dock_seq_feat_dict_' + protTrans_model_name + '_img.pkl')
    joblib.dump(value=dock_seq_feat_dict, filename=filename, compress=3)
    print("\n The dock_seq_feat_dict is saved as: " + filename)
    print("\n######## cleaning all the intermediate stuffs - START ########")
    # remove all the intermediate files in the 'temp_result' and 'temp_per_prot_emb_result' directories which
    # were used in extract_feat_from_preloaded_protTrans() method
    temp_result_dir = os.path.join(root_path, 'temp_result') 
    for temp_file in os.listdir(temp_result_dir):
        os.remove(os.path.join(temp_result_dir, temp_file))
    temp_per_prot_emb_result_dir = os.path.join(root_path, 'temp_per_prot_emb_result') 
    for temp_file in os.listdir(temp_per_prot_emb_result_dir):
        os.remove(os.path.join(temp_per_prot_emb_result_dir, temp_file))
    print("######## cleaning all the intermediate stuffs - DONE ########")



def create_2d_tl_feat_dict_dump(root_path='./', docking_version = '4_0'):
    # load twoD_prot_feat_dict from pkl file
    twoD_prot_feat_dict_fl_nm_with_path = os.path.join(root_path, 'dataset/preproc_data_docking_BM_' + str(docking_version), 'dock_seq_feat_dict_prot_t5_xl_uniref50_img.pkl')
    twoD_prot_feat_dict = joblib.load(twoD_prot_feat_dict_fl_nm_with_path)
    print("twoD_prot_feat_dict loaded ...")
    # trimming twoD_prot_feat_dict so that it occupies less memory (RAM)
    for prot_id in list(twoD_prot_feat_dict.keys()):
        twoD_prot_feat_dict[prot_id]['seq'] = twoD_prot_feat_dict[prot_id]['seq_len'] = None
    # iterate through the twoD_prot_feat_dict
    key_lst_in_twoD_prot_feat_dict = list(twoD_prot_feat_dict.keys())
    no_of_keys_in_twoD_prot_feat_dict = len(key_lst_in_twoD_prot_feat_dict)

    # for itr in range(no_of_keys_in_twoD_prot_feat_dict):
    for itr in range(0, no_of_keys_in_twoD_prot_feat_dict):
        print(f"\n ################# starting {itr}-th iteration out of {no_of_keys_in_twoD_prot_feat_dict-1}")
        prot_id = key_lst_in_twoD_prot_feat_dict[itr]
        prot_2dArr = twoD_prot_feat_dict[prot_id]['seq_2d_feat']
        # save prot_2dArr as a pkl file
        prot_2dArr_file_nm_loc = os.path.join(root_path, 'dataset/preproc_data_docking_BM_' + str(docking_version), 'dock_tl_2d_feat_dict_dump_img', f"prot_id_{prot_id}.pkl")
        joblib.dump(value=prot_2dArr, filename=prot_2dArr_file_nm_loc, compress=0)
    # end of for loop: for itr in range(0, no_of_keys_in_twoD_prot_feat_dict): 




if __name__ == '__main__':
    root_path = os.path.join('/project/root/directory/path/here')
    root_path = os.path.join('/scratch/pralaycs/Shubh_Working_Remote/PPI_Wkspc/PPI_Code/mat_p2ip_prj_working')
    docking_version = '4_0'  # '4_0', '5_5'
    # prepare_tl_feat_for_dock_seq_for_img(root_path
    #                                 ,protTrans_model_path=os.path.join(root_path, '../ProtTrans_Models/')
    #                                 , protTrans_model_name = 'prot_t5_xl_uniref50'
    #                                 , docking_version = docking_version)
    
    create_2d_tl_feat_dict_dump(root_path=root_path, docking_version = docking_version)
